{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fc43ae",
   "metadata": {},
   "source": [
    "# DSCI 525 - Web and Cloud Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea8629",
   "metadata": {},
   "source": [
    "***Milestone 4:*** In this milestone, you will deploy the machine learning model you trained in milestone 3.\n",
    "\n",
    "You might want to go over [this sample project](https://github.ubc.ca/mds-2021-22/DSCI_525_web-cloud-comp_students/blob/master/release/milestone4/sampleproject.ipynb) and get it done before starting this milestone.\n",
    "\n",
    "Milestone 4 checklist :\n",
    "\n",
    "- [ ] Use an EC2 instance.\n",
    "- [ ] Develop your API here in this notebook.\n",
    "- [ ] Copy it to ```app.py``` file in EC2 instance.\n",
    "- [ ] Run your API for other consumers and test among your colleagues.\n",
    "- [ ] Summarize your journey.\n",
    "\n",
    "In this milestone, you will do certain things that you learned. For example...\n",
    "- Login to the instance\n",
    "- Work with Linux and use some basic commands\n",
    "- Configure security groups so that it accepts your webserver requests from your laptop\n",
    "- Configure AWS CLI\n",
    "\n",
    "In some places, I explicitly mentioned these to remind you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c281967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all the packages that you need\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959bcc5",
   "metadata": {},
   "source": [
    "## 1. Develop your API\n",
    "\n",
    "rubric={mechanics:45}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608e655",
   "metadata": {},
   "source": [
    "You probably got how to set up primary URL endpoints from the [sampleproject.ipynb](https://github.ubc.ca/mds-2021-22/DSCI_525_web-cloud-comp_students/blob/master/release/milestone4/sampleproject.ipynb) and have them process and return some data. Here we are going to create a new endpoint that accepts a POST request of the features required to run the machine learning model that you trained and saved in last milestone (i.e., a user will post the predictions of the 25 climate model rainfall predictions, i.e., features,  needed to predict with your machine learning model). Your code should then process this data, use your model to make a prediction, and return that prediction to the user. To get you started with all this, I've given you a template that you should fill out to set up this functionality:\n",
    "\n",
    "***NOTE:*** You won't be able to test the flask module (or the API you make here) unless you go through steps in ```2. Deploy your API```. However, you can make sure that you develop all your functions and inputs properly here.\n",
    "\n",
    "```python\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "## Import any other packages that are needed\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 1. Load your model here\n",
    "model = joblib.load(...)\n",
    "\n",
    "# 2. Define a prediction function\n",
    "def return_prediction(...):\n",
    "\n",
    "    # format input_data here so that you can pass it to model.predict()\n",
    "\n",
    "    return model.predict(...)\n",
    "\n",
    "# 3. Set up home page using basic html\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    # feel free to customize this if you like\n",
    "    return \"\"\"\n",
    "    <h1>Welcome to our rain prediction service</h1>\n",
    "    To use this service, make a JSON post request to the /predict url with 25 climate model outputs.\n",
    "    \"\"\"\n",
    "\n",
    "# 4. define a new route which will accept POST requests and return model predictions\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def rainfall_prediction():\n",
    "    content = request.json  # this extracts the JSON content we sent\n",
    "    prediction = return_prediction(...)\n",
    "    results = {...}  # return whatever data you wish, it can be just the prediction\n",
    "                     # or it can be the prediction plus the input data, it's up to you\n",
    "    return jsonify(results)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c18ff",
   "metadata": {},
   "source": [
    "## 2. Deploy your API\n",
    "\n",
    "rubric={mechanics:40}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d45379",
   "metadata": {},
   "source": [
    "Once your API (app.py) is working, we're ready to deploy it! For this, do the following:\n",
    "\n",
    "1. Setup an EC2 instance. Make sure you add a rule in security groups to accept `All TCP` connections from `Anywhere`. SSH into your EC2 instance from milestone2.\n",
    "2. Make a file `app.py` file in your instance and copy what you developed above in there. \n",
    "\n",
    "    2.1 You can use the Linux editor using ```vi```. More details on vi Editor [here](https://www.guru99.com/the-vi-editor.html). Use your previous learnings, notes, mini videos, etc. You can copy code from your jupyter and paste it into `app.py`.\n",
    "    \n",
    "    2.2 Or else you can make a file in your laptop called app.py and copy it over to your EC2 instance using ```scp```. Eg: ```scp -r -i \"ggeorgeAD.pem\" ~/Desktop/app.py  ubuntu@ec2-xxx.ca-central-1.compute.amazonaws.com:~/```\n",
    "\n",
    "3. Download your model from s3 to your EC2 instance. You want to configure your S3 for this. Use your previous learnings, notes, mini videos, etc.\n",
    "4. You should use one of those package managers to install the dependencies of your API, like `flask`, `joblib`, `sklearn`, etc...\n",
    "\n",
    "    4.1. (Additional help) you can install the required packages inside your terminal.\n",
    "        - Install conda:\n",
    "            wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "            bash Miniconda3-latest-Linux-x86_64.sh\n",
    "        - Install packages (there might be others): \n",
    "            conda install flask scikit-learn joblib\n",
    "\n",
    "5. Now you're ready to start your service, go ahead and run `flask run --host=0.0.0.0 --port=8080`. This will make your service available at your EC2 instance's `Public IPv4 address` on port 8080. Please ensure that you run this from where ```app.py``` and ```model.joblib``` reside.\n",
    "6. You can now access your service by typing your EC2 instances `public IPv4 address` append with `:8080` into a browser, so something like `http://Public IPv4 address:8080`. From step 4, you might notice that flask output saying \"Running on http://XXXX:8080/ (Press CTRL+C to quit)\", where XXXX is `Private IPv4 address`, and you want to replace it with the `Public IPv4 address`\n",
    "7. You should use `curl` to send a post request to your service to make sure it's working as expected.\n",
    ">EG: curl -X POST http://your_EC2_ip:8080/predict -d '{\"data\":[1,2,3,4,53,11,22,37,41,53,11,24,31,44,53,11,22,35,42,53,12,23,31,42,53]}' -H \"Content-Type: application/json\"\n",
    "\n",
    "8. Now, what happens if you exit your connection with the EC2 instance? Can you still reach your service?\n",
    "9. We could use several options to help us persist our server even after we exit our shell session. We'll be using `screen`. `screen` will allow us to create a separate session within which we can run `flask` and won't shut down when we exit the main shell session. Read [this](https://linuxize.com/post/how-to-use-linux-screen/) to learn more on ```screen```.\n",
    "10. Now, create a new `screen` session (think of this as a new, separate shell), using: `screen -S myapi`. If you want to list already created sessions do ```screen -list```. If you want to get into an existing ```screen -x myapi```.\n",
    "11. Within that session, start up your flask app. You can then exit the session by pressing `Ctrl + A then press D`. Here you are detaching the session, once you log back into EC2 instance you can attach it using ```screen -x myapi```.\n",
    "12. Feel free to exit your connection with the EC2 instance now and try reaccessing your service with `curl`. You should find that the service has now persisted!\n",
    "13. ***CONGRATULATIONS!!!*** You have successfully got to the end of our milestones. Move to Task 3 and submit it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fbf7c",
   "metadata": {},
   "source": [
    "## 3. Summarize your journey from Milestone 1 to Milestone 4\n",
    "rubric={mechanics:10}\n",
    ">There is no format or structure on how you write this. (also, no minimum number of words).  It's your choice on how well you describe it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b48c8-76db-4105-a780-d385bdf5dcfa",
   "metadata": {},
   "source": [
    "**Milestone 1**:\n",
    "\n",
    "Milestone 1 includes working with large data sets using pandas and vanilla CSV files, then moving on to exploring different options/ tools to tackle big data on personal laptops. \n",
    "\n",
    "Main steps are:\n",
    "1. We fetched the raw data from figshare (~6GB), and combined all files into one .csv file using pandas.\n",
    "2. Then, we performed a simple EDA in Python with the function `value_counts`. We tried two approaches to reduce memory usage while performing the EDA: (1) loading just columns that we want, and (2) loading in chunks. We could observe that the first approach significantly reduced Wall Time while the second one did not give us the same effect.\n",
    "3. Lastly, we performed the same EDA in R. We chose to work with Feather to transfer the data frame from Python to R. Amazingly, Feather reduced the data size from ~6GB to ~1GB, and performed much faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca06cb9-c718-46a6-b9cb-109258fffbcc",
   "metadata": {},
   "source": [
    "**Milestone 2**:\n",
    "\n",
    "Milestone 2 includes setting up a server in the cloud, creating a collaborative environment for our team there, then moving our data to the cloud. \n",
    "\n",
    "Main steps are:\n",
    "1. We set up our EC2 instance and JupyterHub. We then added all team members to the EC2 instance and created a common data folder with the same access granted to each member. We also created a S3 bucket as our storage space.\n",
    "2. Then, we downloaded the data that we wrangled in milestone 1 into the server’s shared folder, and moved it to the S3 bucket through the AWS CLI.\n",
    "3. Lastly, we got the data from S3 and wrangled it more to make the data ready for machine learning (ML). Specifically, we filtered for Sydney data only, dropped unused columns, and saved the data into a .csv file. We then saved the processed file back into S3 for later ML training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a8b59-6bf2-4d99-aa4b-c06e69c48b6d",
   "metadata": {},
   "source": [
    "**Milestone 3**:\n",
    "\n",
    "Milestone 3 includes setting up our EMR cluster with Spark, then developing a ML model to deploy in the cloud for milestone 4.\n",
    "\n",
    "Main steps are:\n",
    "\n",
    "1. We set up our EMR cluster using the AWS management console release 6.5.0. We set core instances to be 0, master node to be 1, and instance size to be m5.xlarge. After disabling auto-termination, we selected the key pair from milestone 2. We went with the default for EC2 security group. It took ~15 minutes for the cluster to start.\n",
    "2. Then, we set up our browser and jupyter environment. We connected to the master node by opening an SSH Tunnel and  configuring FoxyProxy for Firefox to set up a proxy. We were then able to connect to the master node from our laptop terminals. \n",
    "3. Lastly, we developed a ML model using two libraries (1) scikit-learn, and (2) MLib. Specifically, in both approaches, we read the data from our S3 bucket, dropped rows with missing values, split the data into train and test sets, performed an EDA, and training ensemble ML model using random forest. After tuning hyperparameters using MLib, we settled on using a RandomForestRegressor model with numTrees set to 100, maxDepth to 5, and bootstrap to True, resulting in a RMSE score of 8.17. The final model was uploaded to our S3 server in preparation for deployment in milestone 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6156e96-eb21-4b0d-bb24-4ca7f7251f48",
   "metadata": {},
   "source": [
    "**Milestone 4**:\n",
    "\n",
    "Milestone 4 includes developing and deploying an API for our prediction model that was trained during milestone 3. \n",
    "\n",
    "Main steps are:\n",
    "\n",
    "1. We wrote a Python script to set up an endpoint that accepts a POST request of the features and returns model predictions using flask. By that, our API app was created. \n",
    "2. Then, we connected to our EC2 instance that was set up during milestone 2 and moved our ML model from our S3 server there. Once the required packages were installed, we started our service. We then used several options to help us persist our server after exiting our shell session. After confirming that the service had persisted, we could be confident that our API was developed and deployed successfully. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2fe94a",
   "metadata": {},
   "source": [
    "## 4. Submission instructions\n",
    "rubric={mechanics:5}\n",
    "\n",
    "In the textbox provided on Canvas please put a link where TAs can find the following-\n",
    "- [ ] This notebook with solution to ```1 & 3```\n",
    "- [ ] Screenshot from \n",
    "    - [ ] Output after trying curl. Here is a [sample](https://github.ubc.ca/mds-2021-22/DSCI_525_web-cloud-comp_students/blob/master/release/milestone4/images/curl_deploy_sample.png). This is just an example; your input/output doesn't have to look like this, you can design the way you like. But at a minimum, it should show your prediction value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d02d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
